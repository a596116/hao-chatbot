<template>
  <div class="chat-sender" :class="{ 'is-loading': loading }">
    <Sender
      ref="senderRef"
      v-model="messageText"
      :placeholder="placeholder"
      :loading="loading"
      :submit-btn-disabled="!messageText.trim()"
      clearable
      allow-speech
      variant="updown"
      @submit="handleSubmit"
      @cancel="handleCancel"
      @recordingChange="handleRecordingChange"
    >
      <template #prefix>
        <AttachmentMenu @select="handleAttachmentSelect" />
      </template>
    </Sender>
  </div>
</template>

<script setup lang="ts">
import { ref, onMounted, watch } from 'vue'
import { Sender } from 'vue-element-plus-x'
import AttachmentMenu from './AttachmentMenu.vue'
import type { IAttachmentPayload } from '@/types/type'

interface ChatSenderProps {
  modelValue: string
  placeholder?: string
  loading?: boolean
}

const props = withDefaults(defineProps<ChatSenderProps>(), {
  placeholder: 'è¼¸å…¥è¨Šæ¯... (Shift+Enter æ›è¡Œ)',
  loading: false,
})

const emit = defineEmits<{
  (e: 'update:modelValue', value: string): void
  (e: 'submit'): void
  (e: 'cancel'): void
  (e: 'attachment', payload: IAttachmentPayload): void
}>()

const senderRef = ref<any>()
const messageText = ref(props.modelValue)

// åŒæ­¥ v-model
watch(
  () => props.modelValue,
  (newValue) => {
    messageText.value = newValue
  }
)

watch(messageText, (newValue) => {
  emit('update:modelValue', newValue)
})

// èªéŸ³è­˜åˆ¥ç›¸é—œ
let recognition: any = null
const isRecognizing = ref(false)
let baseText = '' // é–‹å§‹è­˜åˆ¥æ™‚çš„åŸºç¤æ–‡æœ¬
let finalText = '' // å·²ç¢ºèªçš„æœ€çµ‚æ–‡æœ¬
let interimText = '' // ç•¶å‰çš„è‡¨æ™‚è­˜åˆ¥æ–‡æœ¬

// åˆå§‹åŒ–èªéŸ³è­˜åˆ¥
const initSpeechRecognition = () => {
  const SpeechRecognition =
    (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition

  if (!SpeechRecognition) {
    console.warn('âš ï¸ æ‚¨çš„ç€è¦½å™¨ä¸æ”¯æ´èªéŸ³è­˜åˆ¥åŠŸèƒ½')
    return
  }

  recognition = new SpeechRecognition()

  // é€£çºŒè­˜åˆ¥æ¨¡å¼
  recognition.continuous = true

  // è¿”å›å³æ™‚çµæœ
  recognition.interimResults = true

  // æœ€å¤§å€™é¸çµæœæ•¸
  recognition.maxAlternatives = 1

  // é–‹å§‹è­˜åˆ¥äº‹ä»¶
  recognition.onstart = () => {
    console.log('ğŸ¤ èªéŸ³è­˜åˆ¥å·²é–‹å§‹')
    isRecognizing.value = true
    baseText = messageText.value
    finalText = ''
    interimText = ''
  }

  // è­˜åˆ¥çµæœäº‹ä»¶
  recognition.onresult = (event: any) => {
    let newInterimTranscript = ''
    let newFinalTranscript = ''

    for (let i = event.resultIndex; i < event.results.length; i++) {
      const transcript = event.results[i][0].transcript
      if (event.results[i].isFinal) {
        newFinalTranscript += transcript
      } else {
        newInterimTranscript += transcript
      }
    }

    if (newFinalTranscript) {
      finalText += (finalText ? ' ' : '') + newFinalTranscript
      interimText = ''
      console.log('âœ… è­˜åˆ¥å®Œæˆï¼š', newFinalTranscript)
    }

    if (newInterimTranscript) {
      interimText = newInterimTranscript
      console.log('ğŸ”„ å³æ™‚è­˜åˆ¥ï¼š', newInterimTranscript)
    } else {
      interimText = ''
    }

    const parts = [baseText, finalText, interimText].filter(Boolean)
    messageText.value = parts.join(' ').trim()
  }

  // è­˜åˆ¥çµæŸäº‹ä»¶
  recognition.onend = () => {
    console.log('â¹ï¸ èªéŸ³è­˜åˆ¥å·²çµæŸ')
    isRecognizing.value = false

    if (interimText) {
      finalText += (finalText ? ' ' : '') + interimText
      interimText = ''
    }

    const parts = [baseText, finalText].filter(Boolean)
    messageText.value = parts.join(' ').trim()

    baseText = ''
    finalText = ''
    interimText = ''
  }

  // éŒ¯èª¤è™•ç†
  recognition.onerror = (event: any) => {
    console.error('âŒ èªéŸ³è­˜åˆ¥éŒ¯èª¤ï¼š', event.error)
    isRecognizing.value = false

    switch (event.error) {
      case 'no-speech':
        console.warn('æœªæª¢æ¸¬åˆ°èªéŸ³è¼¸å…¥')
        break
      case 'audio-capture':
        console.warn('ç„¡æ³•æ•ç²éŸ³é »ï¼Œè«‹æª¢æŸ¥éº¥å…‹é¢¨')
        break
      case 'not-allowed':
        console.warn('éº¥å…‹é¢¨æ¬Šé™è¢«æ‹’çµ•')
        break
      default:
        console.warn('èªéŸ³è­˜åˆ¥ç™¼ç”ŸéŒ¯èª¤')
    }
  }

  console.log('âœ… èªéŸ³è­˜åˆ¥åˆå§‹åŒ–å®Œæˆ')
}

// è™•ç†èªéŸ³è­˜åˆ¥ç‹€æ…‹è®ŠåŒ–
const handleRecordingChange = (recording: boolean) => {
  console.log('ğŸ™ï¸ éŒ„éŸ³ç‹€æ…‹è®ŠåŒ–ï¼š', recording ? 'é–‹å§‹' : 'çµæŸ')

  if (!recognition) {
    console.warn('âš ï¸ èªéŸ³è­˜åˆ¥æœªåˆå§‹åŒ–')
    return
  }

  if (recording) {
    try {
      recognition.start()
    } catch (error) {
      console.error('å•Ÿå‹•èªéŸ³è­˜åˆ¥å¤±æ•—ï¼š', error)
    }
  } else {
    try {
      if (isRecognizing.value) {
        recognition.stop()
      }
    } catch (error) {
      console.error('åœæ­¢èªéŸ³è­˜åˆ¥å¤±æ•—ï¼š', error)
    }
  }
}

const handleSubmit = () => {
  emit('submit')
}

const handleCancel = () => {
  emit('cancel')
}

const handleAttachmentSelect = (payload: IAttachmentPayload) => {
  emit('attachment', payload)
}

const focus = (position: 'start' | 'end' | 'all' = 'end') => {
  senderRef.value?.focus(position)
}

// åˆå§‹åŒ–
onMounted(() => {
  initSpeechRecognition()
})

// æš´éœ²æ–¹æ³•çµ¦çˆ¶çµ„ä»¶
defineExpose({
  focus,
})
</script>

<style scoped>
.chat-sender {
  padding: 8px;
  background: #f5f7fa;
  /* border-top: 1px solid #e8e8e8; */
}

/* è‡ªå®šç¾© Sender çµ„ä»¶æ¨£å¼ */
.chat-sender :deep(.el-sender) {
  width: 100%;
  /* background-color: #fff; */
}

.chat-sender :deep(.el-sender__inner) {
  border-radius: 12px;
  border-color: #e8e8e8;
}

.chat-sender :deep(.el-sender__inner:focus-within) {
  border-color: var(--chatbot-primary, #409eff);
}

.chat-sender :deep(.el-sender__submit-btn) {
  width: 32px;
  height: 32px;
  min-width: 32px;
  padding: 0;
  border-radius: 8px;
  border: none;
  background: transparent;
  color: #666;
  transition: all 0.2s ease;
}

.chat-sender :deep(.el-sender__submit-btn:hover:not(:disabled)) {
  background: rgba(0, 0, 0, 0.05);
  color: #333;
  transform: none;
  box-shadow: none;
}

.chat-sender :deep(.el-sender__submit-btn:active:not(:disabled)) {
  transform: scale(0.96);
}

.chat-sender :deep(.el-sender__submit-btn:disabled) {
  opacity: 0.5;
  cursor: not-allowed;
}

/* çµ±ä¸€æŒ‰éˆ•é¢¨æ ¼ - æ”¹æˆå’Œ attachment æŒ‰éˆ•ä¸€æ¨£çš„æ¨£å¼ */
.chat-sender :deep(.el-send-button .el-button) {
  width: 32px;
  height: 32px;
  min-width: 32px;
  padding: 0;
  border-radius: 8px;
  border: none;
  background: transparent;
  color: #666;
  transition: all 0.2s ease;
}
.chat-sender:not(.is-loading) :deep(.el-send-button:first-child .el-button) {
  background: var(
    --chatbot-primary-gradient,
    linear-gradient(135deg, #409eff 0%, #337ecc 100%)
  );
  color: #fff;
}

.chat-sender
  :deep(.el-send-button:not(:first-child) .el-button:hover:not(:disabled)) {
  background: rgba(0, 0, 0, 0.05);
  color: #333;
  /* transform: none; */
  box-shadow: none;
}

.chat-sender
  :deep(.el-send-button:first-child .el-button:hover:not(:disabled)) {
  /* background: var(
    --chatbot-primary-gradient,
    linear-gradient(135deg, #409eff 0%, #337ecc 100%)
  ); */
  opacity: 0.9;
  color: #fff;
}

.chat-sender :deep(.el-button.is-circle:active:not(:disabled)) {
  transform: scale(0.96);
}

.chat-sender :deep(.el-button.is-circle:disabled) {
  opacity: 0.5;
  cursor: not-allowed;
}
</style>
